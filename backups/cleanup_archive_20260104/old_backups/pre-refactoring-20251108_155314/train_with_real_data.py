#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì‹¤ì œ í‚¤ì›€ API ë°ì´í„°ë¡œ ML ëª¨ë¸ í•™ìŠµ
"""
import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ PYTHONPATHì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from kiwoom_api import KiwoomAPI
from ai.feature_engineer import FeatureEngineer
from ai.ml_model_trainer import MLModelTrainer
import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(name)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

logger = logging.getLogger(__name__)


def fetch_stock_data(api: KiwoomAPI, symbol: str, days: int = 200) -> pd.DataFrame:
    """
    í‚¤ì›€ APIì—ì„œ ì£¼ì‹ ì¼ë´‰ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°

    Args:
        api: KiwoomAPI ì¸ìŠ¤í„´ìŠ¤
        symbol: ì¢…ëª©ì½”ë“œ (ì˜ˆ: '005930' - ì‚¼ì„±ì „ì)
        days: ê°€ì ¸ì˜¬ ì¼ìˆ˜

    Returns:
        DataFrame with columns: date, open, high, low, close, volume
    """
    logger.info(f"ğŸ“Š ì¢…ëª© {symbol}ì˜ ì¼ë´‰ ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘... ({days}ì¼)")

    try:
        all_data = []
        cont_yn = "N"
        next_key = ""
        max_iterations = 10  # ìµœëŒ€ 10ë²ˆ ë°˜ë³µ (ì•ˆì „ì¥ì¹˜)

        # ì—°ì† ì¡°íšŒë¡œ ë°ì´í„° ìˆ˜ì§‘
        for iteration in range(max_iterations):
            result = api.get_daily_chart(
                stock_code=symbol,
                cont_yn=cont_yn,
                next_key=next_key
            )

            # ì‘ë‹µ ë°ì´í„° í™•ì¸
            if 'output2' in result and isinstance(result['output2'], list):
                all_data.extend(result['output2'])
                logger.info(f"   {iteration + 1}ì°¨ ì¡°íšŒ: {len(result['output2'])}ê±´ (ëˆ„ì : {len(all_data)}ê±´)")

            # ì¶©ë¶„í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í–ˆê±°ë‚˜ ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
            if len(all_data) >= days:
                logger.info(f"   ëª©í‘œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(all_data)}ê±´")
                break

            # ì—°ì† ì¡°íšŒ ì •ë³´ í™•ì¸
            if result.get('cont_yn') == 'Y' and result.get('next_key'):
                cont_yn = "Y"
                next_key = result['next_key']
            else:
                logger.info(f"   ë” ì´ìƒ ì¡°íšŒí•  ë°ì´í„° ì—†ìŒ")
                break

        if not all_data or len(all_data) == 0:
            raise ValueError(f"ì¢…ëª© {symbol}ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # DataFrameìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(all_data[:days])  # í•„ìš”í•œ ì¼ìˆ˜ë§Œí¼ë§Œ ì‚¬ìš©

        # ì»¬ëŸ¼ëª… ì •ê·œí™” (í‚¤ì›€ API ì‘ë‹µ í˜•ì‹ì— ë§ê²Œ)
        column_mapping = {
            'stck_bsop_date': 'date',
            'stck_oprc': 'open',
            'stck_hgpr': 'high',
            'stck_lwpr': 'low',
            'stck_clpr': 'close',
            'acml_vol': 'volume'
        }

        # ì‹¤ì œ ì»¬ëŸ¼ëª… í™•ì¸ ë° ë§¤í•‘
        logger.debug(f"   ì›ë³¸ ì»¬ëŸ¼: {df.columns.tolist()}")
        df = df.rename(columns=column_mapping)

        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        required_cols = ['date', 'open', 'high', 'low', 'close', 'volume']
        available_cols = [col for col in required_cols if col in df.columns]

        if len(available_cols) < len(required_cols):
            missing = set(required_cols) - set(available_cols)
            logger.warning(f"   ì¼ë¶€ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
            # ëˆ„ë½ëœ ì»¬ëŸ¼ ì¶”ê°€ (ê¸°ë³¸ê°’ 0)
            for col in missing:
                df[col] = 0

        df = df[required_cols]

        # ë°ì´í„° íƒ€ì… ë³€í™˜
        df['date'] = pd.to_datetime(df['date'], format='%Y%m%d', errors='coerce')
        for col in ['open', 'high', 'low', 'close', 'volume']:
            df[col] = pd.to_numeric(df[col], errors='coerce')

        # NaN ì œê±°
        df = df.dropna()

        # ë‚ ì§œìˆœ ì •ë ¬ (ì˜¤ë˜ëœ ê²ƒë¶€í„°)
        df = df.sort_values('date').reset_index(drop=True)

        logger.info(f"âœ… {len(df)}ì¼ì¹˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ")
        logger.info(f"   ê¸°ê°„: {df['date'].min()} ~ {df['date'].max()}")
        logger.info(f"   ìµœê·¼ ì¢…ê°€: {df['close'].iloc[-1]:,.0f}ì›")

        return df

    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        raise


def create_training_data(price_data: pd.DataFrame, symbol: str) -> pd.DataFrame:
    """
    ê°€ê²© ë°ì´í„°ì—ì„œ ML í•™ìŠµìš© ë°ì´í„° ìƒì„±

    Args:
        price_data: ê°€ê²© ë°ì´í„° DataFrame
        symbol: ì¢…ëª©ì½”ë“œ

    Returns:
        Features + Targetì´ í¬í•¨ëœ DataFrame
    """
    logger.info("ğŸ”§ Feature Engineering ì¤‘...")

    feature_engineer = FeatureEngineer()
    features_list = []

    # ê° ì‹œì ì— ëŒ€í•œ features ìƒì„±
    min_required = 60  # FeatureEngineerê°€ ìš”êµ¬í•˜ëŠ” ìµœì†Œ ë°ì´í„° ìˆ˜

    for i in range(min_required, len(price_data)):
        try:
            # í•´ë‹¹ ì‹œì ê¹Œì§€ì˜ ë°ì´í„°ë¡œ feature ì¶”ì¶œ
            df_slice = price_data.iloc[:i+1].copy()

            fs = feature_engineer.extract_features(df_slice, symbol=symbol)
            fd = fs.to_dict()

            # Target ìƒì„±: ë‹¤ìŒë‚  ê°€ê²©ì´ ì˜¤ë¥´ë©´ 1, ë‚´ë¦¬ë©´ 0
            if i < len(price_data) - 1:
                future_price = price_data.iloc[i + 1]['close']
                current_price = price_data.iloc[i]['close']
                fd['target'] = 1 if future_price > current_price else 0
                fd['future_return'] = (future_price - current_price) / current_price
            else:
                # ë§ˆì§€ë§‰ ë°ì´í„°ëŠ” ë¯¸ë˜ë¥¼ ëª¨ë¥´ë¯€ë¡œ ì œì™¸
                continue

            features_list.append(fd)

            if (i - min_required + 1) % 50 == 0:
                logger.info(f"   ì§„í–‰: {i - min_required + 1}/{len(price_data) - min_required - 1} ìƒ˜í”Œ ìƒì„±")

        except Exception as e:
            logger.debug(f"ì¸ë±ìŠ¤ {i} ìŠ¤í‚µ: {e}")
            continue

    # DataFrameìœ¼ë¡œ ë³€í™˜
    df = pd.DataFrame(features_list)

    # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
    cols_to_drop = ['symbol', 'timestamp']
    df = df.drop(columns=[c for c in cols_to_drop if c in df.columns])

    logger.info(f"âœ… Feature Engineering ì™„ë£Œ: {len(df)} ìƒ˜í”Œ")
    logger.info(f"   Feature ìˆ˜: {len(df.columns) - 2} ê°œ")

    # Target ë¶„í¬
    target_dist = df['target'].value_counts()
    logger.info(f"   Target ë¶„í¬: ìƒìŠ¹={target_dist.get(1, 0)}, í•˜ë½={target_dist.get(0, 0)}")

    return df


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    logger.info("=" * 80)
    logger.info("ğŸš€ ì‹¤ì œ í‚¤ì›€ API ë°ì´í„°ë¡œ ML ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    logger.info("=" * 80)

    try:
        # 1. í‚¤ì›€ API ì´ˆê¸°í™”
        logger.info("\n1ï¸âƒ£ í‚¤ì›€ API ì—°ê²° ì¤‘...")
        api = KiwoomAPI()
        logger.info("âœ… í‚¤ì›€ API ì´ˆê¸°í™” ì™„ë£Œ")

        # 2. í•™ìŠµí•  ì¢…ëª© ì„¤ì •
        SYMBOLS = [
            '005930',  # ì‚¼ì„±ì „ì
            '000660',  # SKí•˜ì´ë‹‰ìŠ¤
            '035420',  # NAVER
            '051910',  # LGí™”í•™
            '035720',  # ì¹´ì¹´ì˜¤
        ]

        logger.info(f"\nğŸ“‹ í•™ìŠµ ëŒ€ìƒ ì¢…ëª©: {', '.join(SYMBOLS)}")

        # 3. ëª¨ë“  ì¢…ëª©ì˜ ë°ì´í„° ìˆ˜ì§‘ ë° í•™ìŠµ ë°ì´í„° ìƒì„±
        all_training_data = []

        for symbol in SYMBOLS:
            logger.info(f"\n{'='*80}")
            logger.info(f"ğŸ“Š ì¢…ëª©: {symbol}")
            logger.info(f"{'='*80}")

            try:
                # ì¼ë´‰ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                price_data = fetch_stock_data(api, symbol, days=200)

                # í•™ìŠµ ë°ì´í„° ìƒì„±
                training_data = create_training_data(price_data, symbol)

                all_training_data.append(training_data)

                logger.info(f"âœ… {symbol} ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(training_data)} ìƒ˜í”Œ")

            except Exception as e:
                logger.error(f"âŒ {symbol} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue

        if not all_training_data:
            raise ValueError("í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")

        # 4. ëª¨ë“  ì¢…ëª© ë°ì´í„° í†µí•©
        logger.info(f"\n{'='*80}")
        logger.info("ğŸ”— ëª¨ë“  ì¢…ëª© ë°ì´í„° í†µí•© ì¤‘...")
        df_combined = pd.concat(all_training_data, ignore_index=True)
        logger.info(f"âœ… í†µí•© ì™„ë£Œ: ì´ {len(df_combined)} ìƒ˜í”Œ")
        logger.info(f"   Feature ìˆ˜: {len(df_combined.columns) - 2} ê°œ")

        # Target ë¶„í¬
        target_dist = df_combined['target'].value_counts()
        logger.info(f"   ì „ì²´ Target ë¶„í¬: ìƒìŠ¹={target_dist.get(1, 0)}, í•˜ë½={target_dist.get(0, 0)}")

        # 5. ëª¨ë¸ í•™ìŠµ
        logger.info(f"\n{'='*80}")
        logger.info("ğŸ¤– ML ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        logger.info(f"{'='*80}")

        trainer = MLModelTrainer(model_type='lightgbm')
        model, metrics = trainer.train(
            df=df_combined,
            target_column='target',
            test_size=0.2
        )

        # 6. ê²°ê³¼ ì¶œë ¥
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“ˆ í•™ìŠµ ì™„ë£Œ!")
        logger.info("=" * 80)
        logger.info(f"âœ… Accuracy: {metrics.accuracy:.1%}")
        logger.info(f"âœ… Precision: {metrics.precision:.1%}")
        logger.info(f"âœ… Recall: {metrics.recall:.1%}")
        logger.info(f"âœ… F1 Score: {metrics.f1_score:.3f}")
        logger.info(f"âœ… ROC AUC: {metrics.roc_auc:.3f}")
        logger.info(f"âœ… Win Rate: {metrics.win_rate:.1%}")
        logger.info(f"âœ… Average Profit: {metrics.avg_profit:.2%}")
        logger.info(f"âœ… Sharpe Ratio: {metrics.sharpe_ratio:.2f}")
        logger.info("=" * 80)
        logger.info(f"âœ… Train Samples: {metrics.train_samples}")
        logger.info(f"âœ… Test Samples: {metrics.test_samples}")
        logger.info(f"âœ… Feature Count: {metrics.feature_count}")
        logger.info(f"âœ… Training Time: {metrics.training_time:.2f}s")

        # 7. ëª¨ë¸ ì €ì¥
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")
        model_path = trainer.save_model(model, metrics)
        logger.info(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")

        # 8. Feature Importance ì¶œë ¥
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š ì£¼ìš” Feature Importance (Top 10):")
        logger.info("=" * 80)
        feature_importance = trainer.get_feature_importance(top_n=10)
        for i, (feat, importance) in enumerate(feature_importance, 1):
            logger.info(f"  {i:2d}. {feat:30s}: {importance:.4f}")

        logger.info("\n" + "=" * 80)
        logger.info("ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        logger.info("=" * 80)

        return 0

    except Exception as e:
        logger.error(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return 1
    finally:
        # API ì—°ê²° ì¢…ë£Œ
        try:
            api.close()
            logger.info("âœ… í‚¤ì›€ API ì—°ê²° ì¢…ë£Œ")
        except:
            pass


if __name__ == '__main__':
    sys.exit(main())
